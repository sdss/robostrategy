#!/usr/bin/env python
# encoding: utf-8
#
# @Author: Michael R. Blanton
# @Date: Sept 26, 2018
# @Filename: rs_assign_final
# @License: BSD 3-Clause
# @Copyright: Michael R. Blanton


from __future__ import division
from __future__ import print_function
from __future__ import absolute_import
from __future__ import unicode_literals

import os
os.environ['OPENBLAS_NUM_THREADS'] = '1'

import argparse
import sys
import multiprocessing
import datetime
import numpy as np
import roboscheduler.cadence as cadence
import robostrategy.field as field
import robostrategy.allocate
import robostrategy.params as params
import sdss_access.path
import pdb
import fitsio
import time
from astropy.coordinates.angle_utilities import angular_separation

sdss_path = sdss_access.path.Path(release='sdss5', preserve_envvars=True)

coordinated_dict = None
noclobber = False

_proc_status = '/proc/%d/status' % os.getpid()

_scale = {'kB': 1024.0, 'mB': 1024.0 * 1024.0,
          'KB': 1024.0, 'MB': 1024.0 * 1024.0}


def _VmB(VmKey):
    '''Private.
    '''
    global _proc_status, _scale
    # get pseudo file  /proc/<pid>/status
    try:
        t = open(_proc_status)
        v = t.read()
        t.close()
    except:
        return 0.0  # non-Linux?
    # get VmKey line e.g. 'VmRSS:  9999  kB\n ...'
    i = v.index(VmKey)
    v = v[i:].split(None, 3)  # whitespace
    if len(v) < 3:
        return 0.0  # invalid format?
    # convert Vm value to bytes
    return float(v[1]) * _scale[v[2]]


def memory(since=0.0):
    '''Return memory usage in bytes.
    '''
    return _VmB('VmSize:') - since


def resident(since=0.0):
    '''Return resident memory usage in bytes.
    '''
    return _VmB('VmRSS:') - since


def stacksize(since=0.0):
    '''Return stack size in bytes.
    '''
    return _VmB('VmStk:') - since


def assign_field(indx):
    print(time.ctime(time.time()))

    fieldid = allocate.field_array['fieldid'][indx]
    if((fieldid % 1) == 0):
        print(fieldid, flush=True)

    field_cadence = allocate.field_array['cadence'][indx].strip()
    
    print("Reading target file", flush=True)
    field_target_file = sdss_path.full('rsFieldTargets',
                                       plan=plan, observatory=observatory,
                                       fieldid=fieldid)

    field_assigned_file = sdss_path.full('rsFieldAssignments',
                                         plan=plan,
                                         observatory=observatory,
                                         fieldid=fieldid)

    if((noclobber is True) & os.path.isfile(field_assigned_file)):
        print("Fieldid {f} exists already".format(f=fieldid))
        return

    print("fieldid {fid}: ".format(fid=fieldid) + str(datetime.datetime.now()), flush=True)
    f = field.Field(filename=field_target_file, verbose=True,
                    fieldid=fieldid, collisionBuffer=collisionBuffer)
    print("fieldid {fid}: ".format(fid=fieldid) + str(datetime.datetime.now()), flush=True)
    icalib = np.where(f.targets['category'] != 'science')[0]
    f.targets['cadence'][icalib] = field_cadence
    print("fieldid {fid}: ".format(fid=fieldid) + str(datetime.datetime.now()), flush=True)
    f.set_field_cadence(field_cadence)
    print("fieldid {fid}: ".format(fid=fieldid) + str(datetime.datetime.now()), flush=True)

    if(f.field_cadence is not None):
        print("Assign targets", flush=True)
        f.assign_science_and_calibs(coordinated_targets=coordinated_dict)

    print("fieldid {fid}: ".format(fid=fieldid) + str(datetime.datetime.now()), flush=True)

    print("Write assignments", flush=True)
    f.tofits(field_assigned_file)

    print("Done fieldid={f}".format(f=fieldid), flush=True)


def pick_one(racen, deccen, fieldidx, d):
    '''
    Given a set of input fields, take the first one
    and remove all fields from further consideration
    that are closer than d (in degrees)
    '''

    all_d = np.array([0])
    oneidx = fieldidx[0]
    ra0 = racen[0]
    dec0 = deccen[0]

    for idx, (ra1, dec1) in enumerate(zip(racen[1:], deccen[1:])):
        new_d = angular_separation(np.deg2rad(ra0), np.deg2rad(dec0),
                                   np.deg2rad(ra1), np.deg2rad(dec1))
        all_d = np.append(all_d, np.rad2deg(new_d))

    return oneidx, racen[all_d > d], deccen[all_d > d], fieldidx[all_d > d]


def find_non_overlapping_fields(racen, deccen, fieldidx, observatory=None):
    if observatory == 'apo':  # copied radii from rs_fields's calls to sloane.Sloane()
        diameter = 1.49 * 2
    elif observatory == 'lco':
        diameter = 0.95 * 2
    else:
        raise ValueError('{} is not a valid observatory'.format(observatory))

    cur_fields = fieldidx.copy()
    cur_ra = racen.copy()
    cur_dec = deccen.copy()
    max_iter = len(racen)
    counter = 0  # safeguard my while loop

    parallel_idx = np.array([], dtype='int')
    while len(cur_fields) > 0:
        if counter > max_iter:
            raise RunTimeError('While loop exceeds max iteration')
        kp_fid, cur_ra, cur_dec, cur_fields = pick_one(cur_ra, cur_dec, cur_fields, diameter)
        parallel_idx = np.append(parallel_idx, kp_fid)
        counter += 1

    serial_idx = np.setdiff1d(fieldidx, parallel_idx)

    return parallel_idx, serial_idx


def mark_duplicates(done_fieldids, plan=None, observatory=None):

    for fieldid in done_fieldids:
        field_assigned_file = sdss_path.full('rsFieldAssignments',
                                             plan=plan,
                                             observatory=observatory,
                                             fieldid=fieldid)

        allocation = fitsio.read(field_assigned_file, ext=2)
        assigned = np.unique(allocation)  # returns all rsids with assignments
        for one in assigned:
            if one in coordinated_dict.keys():
                coordinated_dict[one] = True


if __name__ == '__main__':

    parser = argparse.ArgumentParser(
        prog=os.path.basename(sys.argv[0]),
        description='Final assignment based on allocation')

    parser.add_argument('-p', '--plan', dest='plan',
                        type=str, help='name of plan', required=True)
    parser.add_argument('-o', '--observatory', dest='observatory',
                        type=str, help='apo or lco',
                        choices=['apo', 'lco'], required=True)
    parser.add_argument('-s', '--start', dest='start',
                        type=np.int32, help='field to start', required=False,
                        default=0)
    parser.add_argument('-e', '--end', dest='end',
                        type=np.int32, help='field to end', required=False,
                        default=-1)
    parser.add_argument('-c', '--coordinate', dest='coordinate',
                        default=False, action='store_true',
                        help='coordinate target overlap')
    parser.add_argument('-k', '--no-clobber', dest='noclobber',
                        help='do not clobber', required=False,
                        default=False, action='store_true')
    parser.add_argument('-M', '--no-multiprocess', dest='nomultiprocess',
                        help='do not use multiprocess', required=False,
                        default=False, action='store_true')

    args = parser.parse_args()
    plan = args.plan
    observatory = args.observatory
    start = args.start
    end = args.end
    coordinate = args.coordinate
    noclobber = args.noclobber
    nomultiprocess = args.nomultiprocess
    print(time.ctime(time.time()))

    rsParams = params.RobostrategyParams(plan=plan)
    if('Rotate' in rsParams.cfg['Fields']):
        rotate = True
        paname = rsParams.cfg['Fields']['Rotate']
    else:
        rotate = False
        paname = ''

    collisionBuffer = 2.
    if('Assignment' in rsParams.cfg):
        if('collisionBuffer' in rsParams.cfg['Assignment']):
            collisionBuffer = np.float32(rsParams.cfg['Assignment']['collisionBuffer'])

    cadencelist = cadence.CadenceList()
    cadences_file = sdss_path.full('rsCadences', plan=plan,
                                   observatory=observatory)
    cadencelist.fromfits(filename=cadences_file, unpickle=True)

    allocate_file = sdss_path.full('rsAllocation', plan=plan,
                                   observatory=observatory)
    allocate = robostrategy.allocate.AllocateLST(filename=allocate_file,
                                                 observatory=observatory)

    if(end < 0):
        end = allocate.field_array['fieldid'].max()
    ikeep = np.where((allocate.field_array['fieldid'] >= start) &
                     (allocate.field_array['fieldid'] <= end))[0]


# NEED TO DO SOME REWRITING. assign_field works on field index
    if coordinate:
        print('Running non-overlapping fields')
        print(time.ctime(time.time()))
        parallel_ids, sequential_ids = find_non_overlapping_fields(allocate.field_array['racen'][ikeep], 
                                                                   allocate.field_array['deccen'][ikeep], 
                                                                   ikeep,observatory=observatory)

        np.random.shuffle(parallel_ids)
        if(nomultiprocess):
            for i in parallel_ids:
                assign_field(i)
        else:
            with multiprocessing.Pool() as pool:
                pool.map(assign_field, parallel_ids)

        print("Identifying duplicate targets")
        print(time.ctime(time.time()))
        target_covered_file = sdss_path.full('rsTargets', plan=plan,
                                             observatory=observatory).replace('rsTargets', 'rsTargetsCovered')
        targets_covered = fitsio.read(target_covered_file)
        in_hex = targets_covered['within_hex']
        duplicated = targets_covered[in_hex > 1]
        coordinated_dict = {x:False for x in duplicated['rsid']}

        print("Updating Duplicate targets observed in fields")
        print(time.ctime(time.time()))
        mark_duplicates(allocate.field_array['fieldid'][parallel_ids], plan=plan,
                        observatory=observatory)  # coordinated_dict is global

        print("Running remaining fields sequentially")
        print(time.ctime(time.time()))
        for i in sequential_ids:
            assign_field(i)
    else:
        np.random.shuffle(ikeep)
        if(nomultiprocess):
            for i in ikeep:
                assign_field(i)
        else:
            with multiprocessing.Pool() as pool:
                pool.map(assign_field, ikeep)

    print('DONE: rs_assign_final')
    print(time.ctime(time.time()))
